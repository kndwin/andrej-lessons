{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b0ada0b1-a9f3-4a4c-a452-70f5a4442fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e067b7d-ad9e-460f-a62a-ed7d26c2b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file\n",
    "names = open(\"names.txt\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d246866-cb94-4d3d-8576-3462057140ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n.', 13526), ('a.', 13280), ('.a', 8820), ('e.', 7966), ('.k', 5926), ('an', 5438), ('.m', 5076), ('i.', 4978), ('.j', 4844), ('h.', 4818)]\n"
     ]
    }
   ],
   "source": [
    "# Extract bigrams and loop through them\n",
    "def getCharPairs(name):\n",
    "    pairs = [(\".\", name[0])]\n",
    "    for i in range(len(name)-1):\n",
    "        pairs.append([name[i], name[i+1]])\n",
    "    pairs.append([n[len(n)-1], \".\"])\n",
    "    return pairs\n",
    "\n",
    "pairCount = dict()\n",
    "for n in names:\n",
    "    charPairs = getCharPairs(n)\n",
    "    charPairs.insert(0, [\".\", n[0]])\n",
    "    charPairs.append([n[len(n)-1], \".\"])\n",
    "\n",
    "    for pairs in charPairs:\n",
    "        p = \"\".join(pairs)\n",
    "        pairCount[p] =  pairCount.get(p, 0) + 1\n",
    "\n",
    "print(sorted(pairCount.items(), key=lambda kv:-kv[1])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd04b37a-37dc-49b3-80cf-454b08e4f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct probablity matrix of all character pairs\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "N = torch.ones(28, 28, dtype=torch.int)\n",
    "alphabet = list('.abcdefghijklmnopqrstuvwxyz')\n",
    "s2i = {c: i for i, c in enumerate(alphabet)}\n",
    "i2s = {i: c for i, c in enumerate(alphabet)}\n",
    "\n",
    "for n in names:\n",
    "    for pairs in getCharPairs(n):\n",
    "        row = s2i[pairs[0]]\n",
    "        col = s2i[pairs[1]]\n",
    "        N[row, col] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "072e793e-e0fa-43dc-aea5-cc3a55be8522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".da.\n",
      ".amnn.\n",
      ".sen.\n"
     ]
    }
   ],
   "source": [
    "# Understand broadcasting rules\n",
    "# Initialize with ones to smooth the model \n",
    "P = (N+1).float()\n",
    "P /= P.sum(1, keepdim=True)\n",
    "\n",
    "# Model inference with multinomial picking(?)\n",
    "for i in range(3):\n",
    "    dream_word = [\".\"]\n",
    "    while True:\n",
    "        ix = s2i[dream_word[-1]]\n",
    "        p = torch.multinomial(P[ix], num_samples=1)\n",
    "        dream_word.append(i2s[p.item()])\n",
    "        if (i2s[p.item()] == '.'):\n",
    "            break\n",
    "    print(\"\".join(dream_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5deabffe-a741-4fe6-acfb-c2736cad91c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.3402\n",
      "2.0680\n"
     ]
    }
   ],
   "source": [
    "# Calculate negative log likelihood\n",
    "total_longprob = 0\n",
    "count = 0\n",
    "for n in [\"je\"]:\n",
    "    charPairs = getCharPairs(n)\n",
    "    charPairs.insert(0, [\".\", n[0]])\n",
    "    charPairs.append([n[len(n)-1], \".\"])\n",
    "    for p in charPairs:\n",
    "        ix1, ix2 = s2i[p[0]], s2i[p[1]]\n",
    "        cp = \"\".join(p)\n",
    "        prob = P[ix1][ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        total_longprob += logprob\n",
    "        count += 1\n",
    "        \n",
    "        # print(f'{cp}: {prob:.4f} - {logprob:.4f}')\n",
    "\n",
    "print(f'{total_longprob.item():.4f}')\n",
    "print(f'{-total_longprob.item()/count:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "17001b63-b3d3-440c-a1a6-3b452a4f46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "xs, ys = [], []\n",
    "for n in names:\n",
    "    for p in getCharPairs(n):\n",
    "        ix1, ix2 = s2i[p[0]], s2i[p[1]]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "nums = xs.nelement()\n",
    "\n",
    "# Initialize W\n",
    "W = torch.randn((27, 27), requires_grad=True) # (5,27)) @ (27,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "83d1f716-63cf-4f34-a557-1dc4f6e7b0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.630955696105957\n",
      "2.628023624420166\n",
      "2.625411033630371\n",
      "2.6230392456054688\n",
      "2.6208674907684326\n",
      "2.618868112564087\n",
      "2.617018938064575\n",
      "2.6153039932250977\n",
      "2.6137094497680664\n",
      "2.6122241020202637\n",
      "2.610837936401367\n",
      "2.6095428466796875\n",
      "2.608330726623535\n",
      "2.6071949005126953\n",
      "2.6061294078826904\n",
      "2.6051292419433594\n",
      "2.604188919067383\n",
      "2.6033053398132324\n",
      "2.6024727821350098\n",
      "2.6016886234283447\n",
      "2.600949287414551\n",
      "2.6002519130706787\n",
      "2.5995934009552\n",
      "2.598970890045166\n",
      "2.5983827114105225\n",
      "2.5978262424468994\n",
      "2.597299098968506\n",
      "2.5968000888824463\n",
      "2.596327781677246\n",
      "2.595879316329956\n",
      "2.595453977584839\n",
      "2.595050573348999\n",
      "2.5946669578552246\n",
      "2.5943031311035156\n",
      "2.5939571857452393\n",
      "2.5936279296875\n",
      "2.5933148860931396\n",
      "2.5930168628692627\n",
      "2.5927329063415527\n",
      "2.5924630165100098\n",
      "2.592205762863159\n",
      "2.5919606685638428\n",
      "2.591726541519165\n",
      "2.591503381729126\n",
      "2.5912907123565674\n",
      "2.591087579727173\n",
      "2.5908939838409424\n",
      "2.5907087326049805\n",
      "2.590531826019287\n",
      "2.590363025665283\n",
      "2.5902013778686523\n",
      "2.5900471210479736\n",
      "2.5898993015289307\n",
      "2.5897581577301025\n",
      "2.589622974395752\n",
      "2.589493751525879\n",
      "2.5893702507019043\n",
      "2.5892515182495117\n",
      "2.5891385078430176\n",
      "2.5890297889709473\n",
      "2.58892560005188\n",
      "2.5888259410858154\n",
      "2.588730573654175\n",
      "2.5886387825012207\n",
      "2.5885512828826904\n",
      "2.5884673595428467\n",
      "2.5883865356445312\n",
      "2.5883092880249023\n",
      "2.5882349014282227\n",
      "2.5881638526916504\n",
      "2.5880954265594482\n",
      "2.5880298614501953\n",
      "2.5879666805267334\n",
      "2.5879065990448\n",
      "2.587848424911499\n",
      "2.5877928733825684\n",
      "2.5877397060394287\n",
      "2.5876882076263428\n",
      "2.5876386165618896\n",
      "2.5875914096832275\n",
      "2.58754563331604\n",
      "2.5875020027160645\n",
      "2.5874600410461426\n",
      "2.5874197483062744\n",
      "2.587380886077881\n",
      "2.587343215942383\n",
      "2.5873074531555176\n",
      "2.587273120880127\n",
      "2.587239980697632\n",
      "2.587207794189453\n",
      "2.587177276611328\n",
      "2.5871477127075195\n",
      "2.5871193408966064\n",
      "2.587092161178589\n",
      "2.5870659351348877\n",
      "2.587040424346924\n",
      "2.5870165824890137\n",
      "2.5869927406311035\n",
      "2.586970329284668\n",
      "2.5869486331939697\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "for k in range(100):\n",
    "    # Forward pass\n",
    "    # Softmax (converts [0..N] to [0..1] that adds to 1\n",
    "    xenc = F.one_hot(xs, num_classes=27).float() \n",
    "    logits = (xenc @ W) \n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(nums), ys].log().mean() + 0.01*(W**2).mean()\n",
    "\n",
    "    # Backward backpropagation\n",
    "    W.grad = None # zero grad\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    W.data += -50 * W.grad\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f4a4be15-1073-44b9-ac4f-d68a08d3f762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".oxrerea.\n",
      ".nayjrhmniejtrtrhs.\n",
      ".aecalpknetejkciedykhnwla.\n"
     ]
    }
   ],
   "source": [
    "# Model inference with multinomial picking with new trained probs\n",
    "for i in range(3):\n",
    "    dream_word = [\".\"]\n",
    "    while True:\n",
    "        ix = s2i[dream_word[-1]]\n",
    "        p = torch.multinomial(probs[ix], num_samples=1)\n",
    "        dream_word.append(i2s[p.item()])\n",
    "        if (i2s[p.item()] == '.'):\n",
    "            break\n",
    "    print(\"\".join(dream_word))\n",
    "\n",
    "# still weird lol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "82dcdc05-e74d-4391-8548-b2533f60350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 0 (.), label: 5 (e)\n",
      "  prob for label (e) given input (.): 0.0478\n",
      "  nll: 3.0412001609802246\n",
      "input: 5 (e), label: 13 (m)\n",
      "  prob for label (m) given input (e): 0.0376\n",
      "  nll: 3.2797460556030273\n",
      "input: 13 (m), label: 13 (m)\n",
      "  prob for label (m) given input (m): 0.0246\n",
      "  nll: 3.7051374912261963\n",
      "input: 13 (m), label: 1 (a)\n",
      "  prob for label (a) given input (m): 0.3893\n",
      "  nll: 0.9433497190475464\n",
      "input: 1 (a), label: 0 (.)\n",
      "  prob for label (.) given input (a): 0.1960\n",
      "  nll: 1.6298680305480957\n",
      "Avg NLL: 2.51986026763916 - Mean: 2.51986026763916\n"
     ]
    }
   ],
   "source": [
    "# Figure out the negative log likelihood\n",
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    xi, yi = xs[i].item(), ys[i].item()\n",
    "    xc, yc = i2s[xi], i2s[yi]\n",
    "    prob = probs[i, yi]\n",
    "    logp = torch.log(prob)\n",
    "    nlls[i] = -logp\n",
    "    print(f\"input: {xi} ({xc}), label: {yi} ({yc})\")\n",
    "    print(f\"  prob for label ({yc}) given input ({xc}): {prob:.4f}\")\n",
    "    print(f\"  nll: {-logp}\")\n",
    "print(f\"Avg NLL: {nlls.sum()/5} - Mean: {nlls.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
