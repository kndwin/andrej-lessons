{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b0ada0b1-a9f3-4a4c-a452-70f5a4442fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e067b7d-ad9e-460f-a62a-ed7d26c2b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file\n",
    "names = open(\"names.txt\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d246866-cb94-4d3d-8576-3462057140ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n.', 13526), ('a.', 13280), ('.a', 8820), ('e.', 7966), ('.k', 5926), ('an', 5438), ('.m', 5076), ('i.', 4978), ('.j', 4844), ('h.', 4818)]\n"
     ]
    }
   ],
   "source": [
    "# Extract bigrams and loop through them\n",
    "def getCharPairs(name):\n",
    "    pairs = [(\".\", name[0])]\n",
    "    for i in range(len(name)-1):\n",
    "        pairs.append([name[i], name[i+1]])\n",
    "    pairs.append([n[len(n)-1], \".\"])\n",
    "    return pairs\n",
    "\n",
    "pairCount = dict()\n",
    "for n in names:\n",
    "    charPairs = getCharPairs(n)\n",
    "    charPairs.insert(0, [\".\", n[0]])\n",
    "    charPairs.append([n[len(n)-1], \".\"])\n",
    "\n",
    "    for pairs in charPairs:\n",
    "        p = \"\".join(pairs)\n",
    "        pairCount[p] =  pairCount.get(p, 0) + 1\n",
    "\n",
    "print(sorted(pairCount.items(), key=lambda kv:-kv[1])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd04b37a-37dc-49b3-80cf-454b08e4f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct probablity matrix of all character pairs\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "N = torch.ones(28, 28, dtype=torch.int)\n",
    "alphabet = list('.abcdefghijklmnopqrstuvwxyz')\n",
    "s2i = {c: i for i, c in enumerate(alphabet)}\n",
    "i2s = {i: c for i, c in enumerate(alphabet)}\n",
    "\n",
    "for n in names:\n",
    "    for pairs in getCharPairs(n):\n",
    "        row = s2i[pairs[0]]\n",
    "        col = s2i[pairs[1]]\n",
    "        N[row, col] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "072e793e-e0fa-43dc-aea5-cc3a55be8522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".da.\n",
      ".amnn.\n",
      ".sen.\n"
     ]
    }
   ],
   "source": [
    "# Understand broadcasting rules\n",
    "# Initialize with ones to smooth the model \n",
    "P = (N+1).float()\n",
    "P /= P.sum(1, keepdim=True)\n",
    "\n",
    "# Model inference with multinomial picking(?)\n",
    "for i in range(3):\n",
    "    dream_word = [\".\"]\n",
    "    while True:\n",
    "        ix = s2i[dream_word[-1]]\n",
    "        p = torch.multinomial(P[ix], num_samples=1)\n",
    "        dream_word.append(i2s[p.item()])\n",
    "        if (i2s[p.item()] == '.'):\n",
    "            break\n",
    "    print(\"\".join(dream_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5deabffe-a741-4fe6-acfb-c2736cad91c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.3402\n",
      "2.0680\n"
     ]
    }
   ],
   "source": [
    "# Calculate negative log likelihood\n",
    "total_longprob = 0\n",
    "count = 0\n",
    "for n in [\"je\"]:\n",
    "    charPairs = getCharPairs(n)\n",
    "    charPairs.insert(0, [\".\", n[0]])\n",
    "    charPairs.append([n[len(n)-1], \".\"])\n",
    "    for p in charPairs:\n",
    "        ix1, ix2 = s2i[p[0]], s2i[p[1]]\n",
    "        cp = \"\".join(p)\n",
    "        prob = P[ix1][ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        total_longprob += logprob\n",
    "        count += 1\n",
    "        \n",
    "        # print(f'{cp}: {prob:.4f} - {logprob:.4f}')\n",
    "\n",
    "print(f'{total_longprob.item():.4f}')\n",
    "print(f'{-total_longprob.item()/count:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "17001b63-b3d3-440c-a1a6-3b452a4f46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "xs, ys = [], []\n",
    "for n in names:\n",
    "    for p in getCharPairs(n):\n",
    "        ix1, ix2 = s2i[p[0]], s2i[p[1]]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "nums = xs.nelement()\n",
    "\n",
    "# Initialize W\n",
    "W = torch.randn((27, 27), requires_grad=True) # (5,27)) @ (27,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "83d1f716-63cf-4f34-a557-1dc4f6e7b0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.058008193969727\n",
      "4.105398654937744\n",
      "3.6066832542419434\n",
      "3.3390486240386963\n",
      "3.1814465522766113\n",
      "3.084040641784668\n",
      "3.021763324737549\n",
      "2.980778455734253\n",
      "2.9532668590545654\n",
      "2.9345521926879883\n",
      "2.9217028617858887\n",
      "2.912818431854248\n",
      "2.9066426753997803\n",
      "2.9023311138153076\n",
      "2.8993091583251953\n",
      "2.897184133529663\n",
      "2.895685911178589\n",
      "2.8946261405944824\n",
      "2.8938753604888916\n",
      "2.893341541290283\n",
      "2.8929622173309326\n",
      "2.892690896987915\n",
      "2.8924977779388428\n",
      "2.8923592567443848\n",
      "2.8922600746154785\n",
      "2.892188310623169\n",
      "2.892137050628662\n",
      "2.8921003341674805\n",
      "2.892073631286621\n",
      "2.892054557800293\n",
      "2.892040729522705\n",
      "2.8920304775238037\n",
      "2.8920233249664307\n",
      "2.8920178413391113\n",
      "2.892014265060425\n",
      "2.8920114040374756\n",
      "2.8920094966888428\n",
      "2.892007827758789\n",
      "2.8920068740844727\n",
      "2.8920061588287354\n",
      "2.8920059204101562\n",
      "2.89200496673584\n",
      "2.8920044898986816\n",
      "2.8920044898986816\n",
      "2.8920044898986816\n",
      "2.8920042514801025\n",
      "2.8920042514801025\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920042514801025\n",
      "2.8920040130615234\n",
      "2.8920042514801025\n",
      "2.8920042514801025\n",
      "2.8920042514801025\n",
      "2.8920044898986816\n",
      "2.8920040130615234\n",
      "2.8920042514801025\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920042514801025\n",
      "2.8920042514801025\n",
      "2.8920037746429443\n",
      "2.8920037746429443\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920037746429443\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920037746429443\n",
      "2.8920037746429443\n",
      "2.8920037746429443\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "for k in range(100):\n",
    "    # Forward pass\n",
    "    # Softmax (converts [0..N] to [0..1] that adds to 1\n",
    "    xenc = F.one_hot(xs, num_classes=27).float() \n",
    "    logits = (xenc @ W) \n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(nums), ys].log().mean() + 1*(W**2).mean()\n",
    "\n",
    "    # Backward backpropagation\n",
    "    W.grad = None # zero grad\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    W.data += -50 * W.grad\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f4a4be15-1073-44b9-ac4f-d68a08d3f762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".oxrerea.\n",
      ".nayjrhmniejtrtrhs.\n",
      ".aecalpknetejkciedykhnwla.\n"
     ]
    }
   ],
   "source": [
    "# Model inference with multinomial picking with new trained probs\n",
    "for i in range(3):\n",
    "    dream_word = [\".\"]\n",
    "    while True:\n",
    "        ix = s2i[dream_word[-1]]\n",
    "        p = torch.multinomial(probs[ix], num_samples=1)\n",
    "        dream_word.append(i2s[p.item()])\n",
    "        if (i2s[p.item()] == '.'):\n",
    "            break\n",
    "    print(\"\".join(dream_word))\n",
    "\n",
    "# still weird lol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "82dcdc05-e74d-4391-8548-b2533f60350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 0 (.), label: 5 (e)\n",
      "  prob for label (e) given input (.): 0.0478\n",
      "  nll: 3.0412001609802246\n",
      "input: 5 (e), label: 13 (m)\n",
      "  prob for label (m) given input (e): 0.0376\n",
      "  nll: 3.2797460556030273\n",
      "input: 13 (m), label: 13 (m)\n",
      "  prob for label (m) given input (m): 0.0246\n",
      "  nll: 3.7051374912261963\n",
      "input: 13 (m), label: 1 (a)\n",
      "  prob for label (a) given input (m): 0.3893\n",
      "  nll: 0.9433497190475464\n",
      "input: 1 (a), label: 0 (.)\n",
      "  prob for label (.) given input (a): 0.1960\n",
      "  nll: 1.6298680305480957\n",
      "Avg NLL: 2.51986026763916 - Mean: 2.51986026763916\n"
     ]
    }
   ],
   "source": [
    "# Figure out the negative log likelihood\n",
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    xi, yi = xs[i].item(), ys[i].item()\n",
    "    xc, yc = i2s[xi], i2s[yi]\n",
    "    prob = probs[i, yi]\n",
    "    logp = torch.log(prob)\n",
    "    nlls[i] = -logp\n",
    "    print(f\"input: {xi} ({xc}), label: {yi} ({yc})\")\n",
    "    print(f\"  prob for label ({yc}) given input ({xc}): {prob:.4f}\")\n",
    "    print(f\"  nll: {-logp}\")\n",
    "print(f\"Avg NLL: {nlls.sum()/5} - Mean: {nlls.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
